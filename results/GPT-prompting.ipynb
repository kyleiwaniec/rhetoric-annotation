{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def77e51-ee06-49bf-9789-b03f88b8b83b",
   "metadata": {},
   "source": [
    "# Re-prompting GPT - V3\n",
    "The results from these are listed in the FT column in the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b14a2-df1e-4537-9a46-0afa4eb63ec1",
   "metadata": {},
   "source": [
    "### Conda environment: transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7803f73-80b3-40fe-bd65-161ff02f9448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /Users/kylehamilton/opt/anaconda3\n",
      "annotation               /Users/kylehamilton/opt/anaconda3/envs/annotation\n",
      "mapping                  /Users/kylehamilton/opt/anaconda3/envs/mapping\n",
      "mlflow                   /Users/kylehamilton/opt/anaconda3/envs/mlflow\n",
      "nlp                      /Users/kylehamilton/opt/anaconda3/envs/nlp\n",
      "pyg                      /Users/kylehamilton/opt/anaconda3/envs/pyg\n",
      "si                       /Users/kylehamilton/opt/anaconda3/envs/si\n",
      "torch                    /Users/kylehamilton/opt/anaconda3/envs/torch\n",
      "transformers          *  /Users/kylehamilton/opt/anaconda3/envs/transformers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b4fbd1-2897-4957-aaa8-def8559d179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import features\n",
    "import ast\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import logging\n",
    "import requests\n",
    "import re\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "import GPT_V2\n",
    "import GPT_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b309e526-10d9-4534-a675-54ed46b0d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e19d4b-4e3f-4d51-a526-7988b79a8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = list(features.f_od.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18b1fc8-baf1-4f1c-b10d-1f1bb9071e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aspect',\n",
       " 'Emphasis',\n",
       " 'Figures_of_argument',\n",
       " 'Figures_of_word_choice',\n",
       " 'Language_of_origin',\n",
       " 'Language_varieties',\n",
       " 'Lexical_and_semantic_fields',\n",
       " 'Modifying_clauses',\n",
       " 'Modifying_phrases',\n",
       " 'Mood',\n",
       " 'New_words_and_changing_uses',\n",
       " 'Parallelism',\n",
       " 'Phrases_built_on_nouns',\n",
       " 'Phrases_built_on_verbs',\n",
       " 'Predication',\n",
       " 'Prosody_and_punctuation',\n",
       " 'Sentence_architecture',\n",
       " 'Series',\n",
       " 'Subject_choices',\n",
       " 'Tense',\n",
       " 'Tropes',\n",
       " 'Verb_choices']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "41d479b2-4b24-47f9-802c-828eb3e87096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_single_gpt_response\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(GPT_V3)\n",
    "\n",
    "def parseRes(x):\n",
    "    try:\n",
    "        result = gpt.parseResponse(x)[1][0]\n",
    "    except:\n",
    "        result = []\n",
    "    return result\n",
    "\n",
    "\n",
    "def fixProperties(s,feature):\n",
    "    new_list = []\n",
    "    if type(s) == str:\n",
    "        s = ast.literal_eval(s) \n",
    "\n",
    "    for l in s:\n",
    "        new_list.append(gpt.mapToProperty(l,feature))\n",
    "        \n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run(data,FEATURE,temp,version):\n",
    "    print(FEATURE)\n",
    "    print(\"=\"*100)\n",
    "    temp = str(temp)\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        responses = []\n",
    "        gpt = GPT_V3.GPT(MODEL)\n",
    "\n",
    "        for row in tqdm(data.iterrows()):\n",
    "            sentence = row[1]['text']\n",
    "            feature = row[1]['feature_id']\n",
    "            sid = row[1]['sentence_id']\n",
    "            promt, response, usage = gpt.get_single_gpt_response(sentence,feature,sid,float(temp))\n",
    "            responses.append([sid, response])\n",
    "\n",
    "        df = pd.DataFrame(responses, columns=['sentence_id','res_'+temp+'_'+version+'_'+str(i)])\n",
    "        \n",
    "        df['property_'+temp+'_'+version+'_'+str(i)] = df['res_'+temp+'_'+version+'_'+str(i)].apply(parseRes)\n",
    "        df['property_'+temp+'_'+version+'_'+str(i)] = df['property_'+temp+'_'+version+'_'+str(i)].apply(lambda s: fixProperties(s,feature))\n",
    "    \n",
    "        data = data.merge(df, how='outer',on='sentence_id')\n",
    "        \n",
    "        data.to_csv(output_path+version+\"_\"+FEATURE+\".csv\",index=None)\n",
    "\n",
    "        print(f\"There were {len(gpt.errors)} errors in round {i}.\")\n",
    "        \n",
    "    # get agreement\n",
    "    \n",
    "    g1 = 'property_'+temp+'_'+version+'_1' \n",
    "    g2 = 'property_'+temp+'_'+version+'_2'\n",
    "    g3 = 'property_'+temp+'_'+version+'_3'\n",
    "\n",
    "    data[\"property_\"+temp+'_'+version+\"_consistency\"] = data.apply(lambda x: utils.calcExactAgreement(x[g1],x[g2],x[g3]),axis=1)\n",
    "    data.to_csv(output_path+version+\"_\"+FEATURE+\".csv\",index=None)\n",
    "        \n",
    "    return sum(data[\"property_\"+temp+'_'+version+\"_consistency\"])/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afbb7e56-e297-43ee-aa20-8eebfe8ab8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuned models:\n",
    "FT_1 = \"ft:gpt-3.5-turbo-1106:personal::8jtK1ntl\"\n",
    "FT_B = \"ft:gpt-3.5-turbo-1106:personal::8kCGsHib\" # only 'perfect' examples\n",
    "FT_25 = \"ft:gpt-3.5-turbo-1106:personal::8kCqqZMf\"\n",
    "FT_Maj = \"ft:gpt-3.5-turbo-1106:personal::8kHQUVJr\" # aspect\n",
    "FT_M_2 = \"ft:gpt-3.5-turbo-1106:personal::8kJH3MlY\" # emphasis\n",
    "FT_M_3 = \"ft:gpt-3.5-turbo-1106:personal::8kJNlyTL\" # figures of argument\n",
    "FT_M_4 = \"ft:gpt-3.5-turbo-1106:personal::8kJHdiWj\" # Figures_of_word_choice\n",
    "FT_M_6 = \"ft:gpt-3.5-turbo-1106:personal::8kSbYB5Z\" # Language_varieties\n",
    "FT_M_7 = \"ft:gpt-3.5-turbo-1106:personal::8kSXEMmV\" # Lexical_and_semantic_fields\n",
    "FT_M_8 = \"ft:gpt-3.5-turbo-1106:personal::8kSZGelp\" # Modifying_clauses\n",
    "# FT_M_9 = \"ft:gpt-3.5-turbo-1106:personal::8kTpo8tH\" # Mood\n",
    "FT_M_9 = \"ft:gpt-3.5-turbo-1106:personal::8krH6MwS\" # Mood\n",
    "FT_M_10 = \"ft:gpt-3.5-turbo-1106:personal::8kTWojhH\" # New_words_and_changing_uses\n",
    "FT_M_11 = \"ft:gpt-3.5-turbo-1106:personal::8kTceGAO\" # Parallelism\n",
    "FT_M_12 = \"ft:gpt-3.5-turbo-1106:personal::8kVWQWJW\" # Phrases_built_on_nouns\n",
    "FT_M_13 = \"ft:gpt-3.5-turbo-1106:personal::8kVFi1Q9\" # Phrases_built_on_verbs\n",
    "FT_M_14 = \"ft:gpt-3.5-turbo-1106:personal::8kVdlK5k\" # Predication\n",
    "FT_M_15 = \"ft:gpt-3.5-turbo-1106:personal::8kYKKQWJ\" # Sentence_architecture\n",
    "FT_M_16 = \"ft:gpt-3.5-turbo-1106:personal::8kYKGlP0\" # Series\n",
    "FT_M_17 = \"ft:gpt-3.5-turbo-1106:personal::8kYdJ0eq\" # Subject_choices\n",
    "\n",
    "FT_M_18 = \"ft:gpt-3.5-turbo-1106:personal::8ka5hSbD\" # Tense\n",
    "FT_M_19 = \"ft:gpt-3.5-turbo-1106:personal::8kaunpHX\" # Tropes\n",
    "FT_M_20 = \"ft:gpt-3.5-turbo-1106:personal::8kZhtRxY\" # Verb_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25516682-06bf-41d7-a6a7-e07a4f275a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kHQUVJr\":\"Aspect\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kJH3MlY\":\"Emphasis\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kJNlyTL\":\"Figures_of_argument\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kJHdiWj\":\"Figures_of_word_choice\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kSbYB5Z\":\"Language_varieties\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kSXEMmV\":\"Lexical_and_semantic_fields\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kSZGelp\":\"Modifying_clauses\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8krH6MwS\":\"Mood\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kTWojhH\":\"New_words_and_changing_uses\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kTceGAO\":\"Parallelism\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kVWQWJW\":\"Phrases_built_on_nouns\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kVFi1Q9\":\"Phrases_built_on_verbs\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kVdlK5k\":\"Predication\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kYKKQWJ\":\"Sentence_architecture\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kYKGlP0\":\"Series\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kYdJ0eq\":\"Subject_choices\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8ka5hSbD\":\"Tense\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kaunpHX\":\"Tropes\",\n",
    "\"ft:gpt-3.5-turbo-1106:personal::8kZhtRxY\":\"Verb_choices\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf11e1c-ffc3-4cc0-b270-e3e8caf5be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate cost of 10 sentences\n",
    "import GPT_V3\n",
    "importlib.reload(utils)\n",
    "importlib.reload(GPT_V3)\n",
    "\n",
    "df = pd.read_csv(\"data/human_gpt_verified/Aspect.csv\")\n",
    "DATA = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2a09c2-f29d-4ac1-862d-a37f9205d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:24,  2.46s/it]\n",
      "10it [00:26,  2.65s/it]\n",
      "10it [00:34,  3.47s/it]\n",
      "10it [00:39,  3.96s/it]\n",
      "10it [01:37,  9.72s/it]\n",
      "10it [00:58,  5.88s/it]\n",
      "10it [00:35,  3.53s/it]\n",
      "10it [00:44,  4.50s/it]\n",
      "10it [01:41, 10.11s/it]\n",
      "10it [00:33,  3.35s/it]\n",
      "10it [00:47,  4.76s/it]\n",
      "10it [00:14,  1.46s/it]\n",
      "10it [00:29,  2.94s/it]\n",
      "10it [00:32,  3.27s/it]\n",
      "10it [00:29,  2.92s/it]\n",
      "10it [00:55,  5.54s/it]\n",
      "10it [00:43,  4.31s/it]\n",
      "10it [01:18,  7.86s/it]\n",
      "10it [00:46,  4.64s/it]\n"
     ]
    }
   ],
   "source": [
    "all_responses = []\n",
    "for k,v in models_dict.items():\n",
    "    FEATURE = v\n",
    "    MODEL = k\n",
    "    gpt = GPT_V3.GPT(MODEL)\n",
    "\n",
    "    for row in tqdm(DATA.iterrows()):\n",
    "            sentence = row[1]['text']\n",
    "            sid = row[1]['sentence_id']\n",
    "            \n",
    "            responses = gpt.get_gpt_response(sentence,FEATURE,sid,0.0,\"\")\n",
    "            all_responses.append(responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2a7df1-4fc3-4f51-bf14-14011a290116",
   "metadata": {},
   "outputs": [],
   "source": [
    "timings = pd.read_csv(\"timings.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d925afd9-7c13-4ade-b3a5-59a3e084ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:24</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:26</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:34</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:39</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:37</td>\n",
       "      <td>9.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00:58</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00:35</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00:44</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01:41</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00:33</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00:47</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00:14</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00:29</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00:32</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00:29</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00:55</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00:43</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01:18</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00:46</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0   00:24   2.46\n",
       "1   00:26   2.65\n",
       "2   00:34   3.47\n",
       "3   00:39   3.96\n",
       "4   01:37   9.72\n",
       "5   00:58   5.88\n",
       "6   00:35   3.53\n",
       "7   00:44   4.50\n",
       "8   01:41  10.11\n",
       "9   00:33   3.35\n",
       "10  00:47   4.76\n",
       "11  00:14   1.46\n",
       "12  00:29   2.94\n",
       "13  00:32   3.27\n",
       "14  00:29   2.92\n",
       "15  00:55   5.54\n",
       "16  00:43   4.31\n",
       "17  01:18   7.86\n",
       "18  00:46   4.64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6caa303-93e1-4038-8d7f-f5896110c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=27, prompt_tokens=120, total_tokens=147)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses[0][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf2110-374f-4daa-8dfc-51159b397750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-3.5-turbo\t$0.0080 / 1K tokens;\tprompt: $0.0030 / 1K tokens;\tcompeletion: $0.0060 / 1K tokens\n",
    "all_responses[0][0][4].completion_tokens * 0.006/1000 + all_responses[0][0][4].prompt_tokens * 0.003/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "317786ce-573b-4d82-a3c6-523e8dd1040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$cost for 10 sentences: 0.7244309999999995 \n",
      "$cost for 20,000 sentences: 1448.861999999999\n"
     ]
    }
   ],
   "source": [
    "cost = 0\n",
    "for responses in all_responses:\n",
    "    for response in responses:\n",
    "        cost += response[4].completion_tokens * 0.006/1000 + response[4].prompt_tokens * 0.003/1000\n",
    "print(\"$cost for 10 sentences:\",cost, \"\\n$cost for 20,000 sentences:\", cost*2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b021f35-ff68-4922-a4f3-bd379e1185e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE = \"Aspect\"\n",
    "MODEL = FT_M_9 #\"gpt-4-1106-preview, gpt-3.5-turbo-instruct, gpt-3.5-turbo-1106\"\n",
    "model_version = \"_FT_Maj_gpt3.5\"\n",
    "version = \"V3\"\n",
    "data_path = \"data/clean-annotated-data/\"\n",
    "output_path = \"data/\"+version+\"/\"+model_version+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "2db66621-b9b1-4bbf-ba5e-ed8bb8f8e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluating models trained on different features\n",
    "alt = \"_FT_Maj\"\n",
    "alt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "89890003-9bdb-4c94-9187-5a13c77c498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = ['Mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "33ebe0a8-90a9-45c0-b426-66e2f083ff3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_gpt_response\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(GPT_V3)\n",
    "gpt = GPT_V3.GPT(MODEL)\n",
    "\n",
    "def parseRes(x,_property):\n",
    "    try:\n",
    "        result = gpt.parseYNResponse(x,_property)\n",
    "    except():\n",
    "        result = []\n",
    "    return result\n",
    "\n",
    "\n",
    "def fixProperties(s,feature):\n",
    "    new_list = []\n",
    "    if type(s) == str:\n",
    "        s = ast.literal_eval(s) \n",
    "\n",
    "    for l in s:\n",
    "        new_list.append(gpt.mapToProperty(l,feature))\n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "def run(data,FEATURE,temp,version,model_version):\n",
    "    temp = str(temp)\n",
    "    \n",
    "    for i in range(2,3):\n",
    "        responses_data = []\n",
    "        gpt = GPT_V3.GPT(MODEL)\n",
    "\n",
    "        for row in tqdm(data.iterrows()):\n",
    "            sentence = row[1]['text']\n",
    "            feature = row[1]['feature_id']\n",
    "            sid = row[1]['sentence_id']\n",
    "            \n",
    "            responses = gpt.get_gpt_response(sentence,feature,sid,float(temp),model_version)\n",
    "            \n",
    "            for res in responses:\n",
    "                responses_data.append([sid, res[1], res[2]])\n",
    "\n",
    "        df = pd.DataFrame(responses_data, columns=['sentence_id','property'+model_version,'res'+model_version+'_'+temp+'_'+version+'_'+str(i)])\n",
    "         \n",
    "        data = data.merge(df, how='outer',on='sentence_id')\n",
    "        data.to_csv(output_path+version+\"_\"+FEATURE+alt+\".csv\",index=None)\n",
    "        \n",
    "        data['property'+model_version+'_'+temp+'_'+version+'_'+str(i)] = \\\n",
    "            data.apply(lambda row: parseRes(row['res'+model_version+'_'+temp+'_'+version+'_'+str(i)],row['property'+model_version]),axis=1) \n",
    "        \n",
    "        data.to_csv(output_path+version+\"_\"+FEATURE+alt+\".csv\",index=None)\n",
    "        \n",
    "        print(f\"There were {len(gpt.errors)} errors in round {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4fcd1de7-9bfd-4674-bf5a-5be4430f96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mood _FT_Maj_gpt3.5 V3 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [01:30,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 errors in round 2.\n",
      "0.13793103448275862\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/vt/g1t9ds3s01z05zs4qg2dngk80000gn/T/ipykernel_44738/2346453323.py:26: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df = df.groupby(['sentence_id']).agg({\n"
     ]
    }
   ],
   "source": [
    "# ADDS THE PROPERTY NAME TO THE RESPONSE OBJECT FOR EASIER READING LATER.\n",
    "def combine(prop, res):\n",
    "    _json_obj = gpt.responseToJson(res)\n",
    "    _json_obj['Property'] = prop\n",
    "    \n",
    "    return _json_obj\n",
    "\n",
    "def removeErrors(s):\n",
    "    if \"parse error\" in s:\n",
    "        s = \"[]\"\n",
    "        \n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "for FEATURE in fs:\n",
    "    df = pd.read_csv(\"data/human_gpt_verified/\"+FEATURE+\".csv\")\n",
    "    df = df[df[\"humans isCorrect\"]>=0]\n",
    "    print(FEATURE, model_version, version, len(df))\n",
    "    run(df,FEATURE,0.0,version,model_version)\n",
    "\n",
    "    # Combine\n",
    "    df = pd.read_csv(output_path+\"/\"+version+\"_\"+FEATURE+alt+\".csv\")\n",
    "    df['property'+model_version+'_0.0_'+version+'_2'] = df['property'+model_version+'_0.0_'+version+'_2'].apply(removeErrors)\n",
    "    df['res'+model_version+'_0.0_'+version+'_2'] = df.apply(lambda x: combine(x['property'+model_version],x['res'+model_version+'_0.0_'+version+'_2']), axis=1)\n",
    "    df['sentence_id'] = df['sentence_id'].apply(lambda x: int(x))\n",
    "\n",
    "    df = df.groupby(['sentence_id']).agg({\n",
    "        'sentence_id':lambda x: x.iloc[0], \n",
    "        'technique':lambda x: x.iloc[0], \n",
    "        'text':lambda x: x.iloc[0], \n",
    "        'feature_id':lambda x: x.iloc[0], \n",
    "        'props_a20':lambda x: x.iloc[0],\n",
    "        'props_a21':lambda x: x.iloc[0], \n",
    "        'props_a22':lambda x: x.iloc[0], \n",
    "        'annotator_consistency':lambda x: x.iloc[0],\n",
    "        'props_gpt4_majority':lambda x: x.iloc[0], \n",
    "        'res_1.0_1':lambda x: x.iloc[0], \n",
    "        'gpt_props_1.0_1':lambda x: x.iloc[0], \n",
    "        'res_1.0_2':lambda x: x.iloc[0],\n",
    "        'gpt_props_1.0_2':lambda x: x.iloc[0], \n",
    "        'res_1.0_3':lambda x: x.iloc[0], \n",
    "        'gpt_props_1.0_3':lambda x: x.iloc[0],\n",
    "        'gpt3.5_1.0_consistency':lambda x: x.iloc[0], \n",
    "        'res_0.2_1':lambda x: x.iloc[0], \n",
    "        'gpt_props_0.2_1':lambda x: x.iloc[0], \n",
    "        'res_0.2_2':lambda x: x.iloc[0],\n",
    "        'gpt_props_0.2_2':lambda x: x.iloc[0], \n",
    "        'res_0.2_3':lambda x: x.iloc[0], \n",
    "        'gpt_props_0.2_3':lambda x: x.iloc[0],\n",
    "        'gpt3.5_0.2_consistency':lambda x: x.iloc[0], \n",
    "        'gpt3.5_0.2_majority':lambda x: x.iloc[0], \n",
    "        'humans isCorrect':lambda x: x.iloc[0],\n",
    "        'gpt isCorrect':lambda x: x.iloc[0], \n",
    "        'comments':lambda x: x.iloc[0], \n",
    "        'ground truth':lambda x: x.iloc[0],\n",
    "        'property'+model_version:list, \n",
    "        'res'+model_version+'_0.0_'+version+'_2':list,\n",
    "        'property'+model_version+'_0.0_'+version+'_2':sum\n",
    "    })\n",
    "    df=df.drop('property'+model_version,axis=1)\n",
    "    df.to_csv(output_path+\"/_\"+version+\"_\"+FEATURE+alt+\".csv\",index=None)\n",
    "    df=pd.read_csv(output_path+\"/_\"+version+\"_\"+FEATURE+alt+\".csv\")\n",
    "    df = df[df[\"humans isCorrect\"]>=0]\n",
    "    df['agreement'] = df.apply(lambda x: utils.calcAgreement(x[\"ground truth\"],x[\"property\"+model_version+\"_0.0_\"+version+\"_2\"]), axis=1)\n",
    "    \n",
    "    print(Counter(df['agreement'])[1]/len(df))\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51da89ba-db2d-405f-aeb9-5ed0811a228f",
   "metadata": {
    "tags": []
   },
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(GPT_V3)\n",
    "gpt = GPT_V3.GPT(MODEL)\n",
    "FEATURE = \"Tropes\"\n",
    "data = pd.read_csv(output_path+version+\"_\"+FEATURE+\".csv\")\n",
    "        \n",
    "data['property'+model_version+'_'+temp+'_'+version+'_'+str(i)] = \\\n",
    "    data.apply(lambda row: parseRes(row['res'+model_version+'_'+temp+'_'+version+'_'+str(i)],row['property'+model_version]),axis=1) \n",
    "\n",
    "data.to_csv(output_path+version+\"_\"+FEATURE+\".csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "928b60d6-25a8-4669-bcfa-d5f4c92c960f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence_id', 'technique', 'text', 'feature_id', 'props_a20',\n",
       "       'props_a21', 'props_a22', 'annotator_consistency',\n",
       "       'props_gpt4_majority', 'res_1.0_1', 'gpt_props_1.0_1', 'res_1.0_2',\n",
       "       'gpt_props_1.0_2', 'res_1.0_3', 'gpt_props_1.0_3',\n",
       "       'gpt3.5_1.0_consistency', 'res_0.2_1', 'gpt_props_0.2_1', 'res_0.2_2',\n",
       "       'gpt_props_0.2_2', 'res_0.2_3', 'gpt_props_0.2_3',\n",
       "       'gpt3.5_0.2_consistency', 'gpt3.5_0.2_majority', 'humans isCorrect',\n",
       "       'gpt isCorrect', 'comments', 'ground truth',\n",
       "       'res_FT_Maj_gpt3.5_0.0_V3_2', 'property_FT_Maj_gpt3.5_0.0_V3_2',\n",
       "       'agreement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e149499-1b88-49cc-87c4-8dc7f0d9acb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(GPT_V3)\n",
    "gpt = GPT_V3.GPT(MODEL)\n",
    "\n",
    "\n",
    "run(df,FEATURE,0.0,version,model_version)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "527d5158-b0af-4995-8349-9ec0a86a4c49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "temp=\"0.0\"\n",
    "i=2\n",
    "df = pd.read_csv(output_path+\"/\"+version+\"_\"+FEATURE+\".csv\")\n",
    "df['property'+model_version+'_'+temp+'_'+version+'_'+str(i)] = df.apply(lambda row: parseRes(row['res'+model_version+'_'+temp+'_'+version+'_'+str(i)],row['property_gpt4']),axis=1) \n",
    "# data.to_csv(output_path+version+\"_\"+FEATURE+\".csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3439940e-583d-4efe-81a7-960a0b0de756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURE = \"Tropes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8055543c-d90a-4d05-9c37-251108faacc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence_id', 'technique', 'text', 'feature_id', 'props_a20',\n",
       "       'props_a21', 'props_a22', 'annotator_consistency',\n",
       "       'props_gpt4_majority', 'res_1.0_1', 'gpt_props_1.0_1', 'res_1.0_2',\n",
       "       'gpt_props_1.0_2', 'res_1.0_3', 'gpt_props_1.0_3',\n",
       "       'gpt3.5_1.0_consistency', 'res_0.2_1', 'gpt_props_0.2_1', 'res_0.2_2',\n",
       "       'gpt_props_0.2_2', 'res_0.2_3', 'gpt_props_0.2_3',\n",
       "       'gpt3.5_0.2_consistency', 'gpt3.5_0.2_majority', 'humans isCorrect',\n",
       "       'gpt isCorrect', 'comments', 'ground truth', 'property_gpt3.5',\n",
       "       'res_gpt3.5_0.0_V3_2', 'property_gpt3.5_0.0_V3_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(output_path+\"/\"+version+\"_\"+FEATURE+\".csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe8d73-c157-421e-b462-5744b4987fc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OPEN THE CSV TO CHECK FOR PARSE ERRORS FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bda6830b-5889-4362-9267-86c9edcc8be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADDS THE PROPERTY NAME TO THE RESPONSE OBJECT FOR EASIER READING LATER.\n",
    "def combine(prop, res):\n",
    "    _json_obj = gpt.responseToJson(res)\n",
    "    _json_obj['Property'] = prop\n",
    "    \n",
    "    return _json_obj\n",
    "\n",
    "def removeErrors(s):\n",
    "    if \"parse error\" in s:\n",
    "        s = \"[]\"\n",
    "        \n",
    "    return ast.literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7ebe4b32-bb01-4f2f-a697-cf7578a08043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e630a56e-c60a-40bc-a62c-2670bb2c1c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_gpt3.5'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7b7d46ff-4e79-4149-b57e-ac54398332ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['property'+model_version+'_0.0_'+version+'_2'] = df['property'+model_version+'_0.0_'+version+'_2'].apply(removeErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f07abc3b-b356-4f36-bcfe-be1456259643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['res'+model_version+'_0.0_'+version+'_2'] = \\\n",
    "    df.apply(lambda x: combine(x['property'+model_version],x['res'+model_version+'_0.0_'+version+'_2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c52d438e-6e57-4a2e-be29-40079e715ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/g1t9ds3s01z05zs4qg2dngk80000gn/T/ipykernel_44738/3356450518.py:3: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df = df.groupby(['sentence_id']).agg({\n"
     ]
    }
   ],
   "source": [
    "df['sentence_id'] = df['sentence_id'].apply(lambda x: int(x))\n",
    "\n",
    "df = df.groupby(['sentence_id']).agg({\n",
    "    'sentence_id':lambda x: x.iloc[0], \n",
    "    'technique':lambda x: x.iloc[0], \n",
    "    'text':lambda x: x.iloc[0], \n",
    "    'feature_id':lambda x: x.iloc[0], \n",
    "    'props_a20':lambda x: x.iloc[0],\n",
    "    'props_a21':lambda x: x.iloc[0], \n",
    "    'props_a22':lambda x: x.iloc[0], \n",
    "    'annotator_consistency':lambda x: x.iloc[0],\n",
    "    'props_gpt4_majority':lambda x: x.iloc[0], \n",
    "    'res_1.0_1':lambda x: x.iloc[0], \n",
    "    'gpt_props_1.0_1':lambda x: x.iloc[0], \n",
    "    'res_1.0_2':lambda x: x.iloc[0],\n",
    "    'gpt_props_1.0_2':lambda x: x.iloc[0], \n",
    "    'res_1.0_3':lambda x: x.iloc[0], \n",
    "    'gpt_props_1.0_3':lambda x: x.iloc[0],\n",
    "    'gpt3.5_1.0_consistency':lambda x: x.iloc[0], \n",
    "    'res_0.2_1':lambda x: x.iloc[0], \n",
    "    'gpt_props_0.2_1':lambda x: x.iloc[0], \n",
    "    'res_0.2_2':lambda x: x.iloc[0],\n",
    "    'gpt_props_0.2_2':lambda x: x.iloc[0], \n",
    "    'res_0.2_3':lambda x: x.iloc[0], \n",
    "    'gpt_props_0.2_3':lambda x: x.iloc[0],\n",
    "    'gpt3.5_0.2_consistency':lambda x: x.iloc[0], \n",
    "    'gpt3.5_0.2_majority':lambda x: x.iloc[0], \n",
    "    'humans isCorrect':lambda x: x.iloc[0],\n",
    "    'gpt isCorrect':lambda x: x.iloc[0], \n",
    "    'comments':lambda x: x.iloc[0], \n",
    "    'ground truth':lambda x: x.iloc[0],\n",
    "    'property'+model_version:list, \n",
    "    'res'+model_version+'_0.0_'+version+'_2':list,\n",
    "    'property'+model_version+'_0.0_'+version+'_2':sum\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fbd23474-54bc-4bd0-b342-17d7cae382e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df.drop('property'+model_version,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "674b99d6-1a7e-4e56-8d49-f19612520d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(output_path+\"/_\"+version+\"_\"+FEATURE+\".csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "45c66e31-8646-4027-b5d5-3a5a8e31d935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(output_path+\"/_\"+version+\"_\"+FEATURE+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "87a5d001-ecff-4029-be3e-e10699acd500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"humans isCorrect\"]>=0]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "92a289de-5d64-4b05-8672-33ead8fa8d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "df['agreement'] = df.apply(lambda x: utils.calcAgreement(x[\"ground truth\"],x[\"property\"+model_version+\"_0.0_\"+version+\"_2\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1b96c4b2-4bdd-46cc-9b65-dd56e738d209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tropes _gpt3.5 V3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15625"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(FEATURE, model_version, version)\n",
    "Counter(df['agreement'])[1]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ee319-2a30-4513-876d-3fb27ff79a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e71401-6d24-45bb-a2c5-ed367017ab72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eec4b-073b-4a95-b8b8-05871a50dbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Figures_of_argument GPT4\n",
    "print(FEATURE, model_version, version)\n",
    "Counter(df['agreement'])[1]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36b686c9-5f7c-460b-84ce-52567a96d558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predication _gpt3.5 V3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subject Predication GPT3.5\n",
    "print(FEATURE, model_version, version)\n",
    "Counter(df['agreement'])[1]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8eaafb3a-7f31-40c7-ab16-0daf2a02772d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subject choices GPT4\n",
    "Counter(df['agreement'])[1]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed070136-3b86-48f0-b4e4-dfab69f4e72e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5666666666666667"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figures_of_argument GPT4\n",
    "Counter(df['agreement'])[1]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae7b13-5f75-4071-b753-477844097f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd9bb20-b9a2-44dc-9601-38e57abff2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fc6ca7d8-7f0a-4396-8a0b-4cd52cac158e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a6193-8ea0-4db2-97f5-4a8fddd836fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08296d81-d107-4878-9a97-eab0dc89f984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
