{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9953b0c6-d1d4-4fab-8ff1-bad25afec3cd",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "Experiment with three different types of fine-tuning data generation:\n",
    "1. **FT-1** - For each feature/property, get one positive and one negative example and explanation.\n",
    "2. **FT-25** - For each feature/property, get 25 positive and 25 negative examples. Do not provide explanation.\n",
    "3. **FT-Maj** - For each sentence and each feature/property in human annotated data, filter out validation set, assign positive to majority vote, assign negative to examples where label is not listed for any annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "5c2f915f-6e58-47a7-8fe9-96a8b8b9870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06342218-fe48-46b9-b853-7953cafb1689",
   "metadata": {},
   "source": [
    "## format for single example:\n",
    "\n",
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, \n",
    "              {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "e5a6f22b-4be7-4927-af1c-ca1f5a74f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "propertiesDict = defaultdict(list)\n",
    "questionsDict = defaultdict()\n",
    "\n",
    "sentenceFeaturesDict = defaultdict(list)\n",
    "sentenceFeaturesList = []\n",
    "\n",
    "with open('../APP/features-sentence.json') as f:\n",
    "    sentenceFeaturesList = json.load(f)\n",
    "\n",
    "    for featureDict in sentenceFeaturesList:\n",
    "        sentenceFeaturesDict[featureDict['key']] = {val:desc for val, desc in zip(featureDict['values'],featureDict['descriptions'])}\n",
    "        questionsDict[featureDict['key']] = featureDict['question']\n",
    "        propertiesDict[featureDict['key']] = featureDict['values']\n",
    "\n",
    "wordFeaturesDict = defaultdict(list)\n",
    "wordFeaturesList = []\n",
    "\n",
    "with open('../APP/features-word.json') as f:\n",
    "    wordFeaturesList = json.load(f)\n",
    "    for featureDict in wordFeaturesList:\n",
    "        wordFeaturesDict[featureDict['key']] = {val:desc for val, desc in zip(featureDict['values'],featureDict['descriptions'])}\n",
    "        questionsDict[featureDict['key']] = featureDict['question']\n",
    "        propertiesDict[featureDict['key']] = featureDict['values'] # dictionary of features and their list of properties\n",
    "\n",
    "featuresDict = sentenceFeaturesDict | wordFeaturesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "a65433c0-b348-4cb0-a4bc-b198a12b2b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k, v in propertiesDict.items():\n",
    "    count += len(v)\n",
    "print(count*2) # number of examples for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "7c6b332c-f679-4d42-99a1-8881bb411af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does the following sentence utilize the _PROP_ mood?'"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionsDict['Mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "584dae53-1c9b-4387-91a4-bc461c3e7b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indicative': \"denotes a mood of verbs expressing a simple statement of a fact. Example: 'Conservative Ben Shapiro told Fox news the verdict was horrifying.'\",\n",
       " 'subjunctive': \"denotes a mood of verbs expressing what is imagined or hypothetical or possible. Example: 'They would be immediate targets should the US and South Korea attack the north.'\",\n",
       " 'exclamatory': \"denotes a mood of verbs expressing surprise, strong emotion, or pain. Example: 'He generated her in His Blood and continually revives her with His Spirit!'\",\n",
       " 'interrogative': \"denotes a mood of verbs expressing questions. Example: 'Peradventure there be fifty righteous within the city: wilt thou also destroy and not spare the place for the fifty righteous that are therein?'\",\n",
       " 'imperative': \"denotes a mood of verbs expressing commands or directives. Example: 'Women everywhere should be furious.'\",\n",
       " 'optative': \"denotes a mood of verbs expressing wishes. Example: 'For their sake, lets hope it works better than this years flu vaccine.'\"}"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDict['Mood']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9e86e-7282-47d9-b994-1a80dc226100",
   "metadata": {},
   "source": [
    "## System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63221f70-00d4-4ad1-b5f0-2b53dc0c23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"gpt-3.5\"\n",
    "SYSTEM_MESSAGE = f\"\"\"You are ChatGPT, a large language model trained by OpenAI, based on the {model_version} architecture. \n",
    "You are also an expert linguist and grammarian specializing in news text. \n",
    "Format your response as a JSON object with 'Answer' and 'Explanation' as the keys. \n",
    "The value of 'Answer' should be either 'yes' or 'no'. Explain your choice in the 'Explanation'.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8641f8-0676-47d0-8b78-73fd6afb7ddc",
   "metadata": {},
   "source": [
    "## User prompt\n",
    "```\n",
    "In the context of '{feature}', '{prop}' {desc}\n",
    "{quest}: {sentence}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd9221-20f8-44f4-b86e-5a9b281a4dc6",
   "metadata": {},
   "source": [
    "## Dataset format\n",
    "\n",
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, \n",
    "              {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df073786-b86e-451f-afae-a6d985c10410",
   "metadata": {},
   "source": [
    "# FT -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d764e1-a561-42fe-a971-ca446e541073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/V3/_gpt4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "a7b95359-7ef3-4ee9-8b4b-2da7dd509b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indicative',\n",
       " 'subjunctive',\n",
       " 'exclamatory',\n",
       " 'interrogative',\n",
       " 'imperative',\n",
       " 'optative']"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE = \"Mood\"\n",
    "PROPS = propertiesDict[FEATURE]\n",
    "PROPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "a4a7168f-08db-449b-a941-14f5dce3909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP = 'allusions'\n",
    "SID = 3990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ae208d47-ec91-4e22-b9cc-9f6c53214594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>technique</th>\n",
       "      <th>text</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>props_a20</th>\n",
       "      <th>props_a21</th>\n",
       "      <th>props_a22</th>\n",
       "      <th>annotator_consistency</th>\n",
       "      <th>props_gpt4_majority</th>\n",
       "      <th>res_1.0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt_props_0.2_3</th>\n",
       "      <th>gpt3.5_0.2_consistency</th>\n",
       "      <th>gpt3.5_0.2_majority</th>\n",
       "      <th>humans isCorrect</th>\n",
       "      <th>gpt isCorrect</th>\n",
       "      <th>comments</th>\n",
       "      <th>ground truth</th>\n",
       "      <th>property_gpt4</th>\n",
       "      <th>res_gpt4_0.0_V3_2</th>\n",
       "      <th>property_gpt4_0.0_V3_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3990</td>\n",
       "      <td>[13]</td>\n",
       "      <td>Last January, parents filed a federal complain...</td>\n",
       "      <td>Language_varieties</td>\n",
       "      <td>['correctness', 'clarity', 'middle']</td>\n",
       "      <td>['correctness', 'clarity', 'middle']</td>\n",
       "      <td>['correctness', 'clarity', 'middle']</td>\n",
       "      <td>True</td>\n",
       "      <td>['correctness', 'middle']</td>\n",
       "      <td>{\\n  \"Properties\": [\"correctness\", \"clarity\", ...</td>\n",
       "      <td>...</td>\n",
       "      <td>['clarity', 'appropriateness']</td>\n",
       "      <td>0</td>\n",
       "      <td>['correctness', 'clarity', 'appropriateness']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['correctness', 'clarity','middle','register s...</td>\n",
       "      <td>allusions</td>\n",
       "      <td>{\\n  \"Answer\": \"no\",\\n  \"Explanation\": \"The se...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id technique                                               text  \\\n",
       "98         3990      [13]  Last January, parents filed a federal complain...   \n",
       "\n",
       "            feature_id                             props_a20  \\\n",
       "98  Language_varieties  ['correctness', 'clarity', 'middle']   \n",
       "\n",
       "                               props_a21  \\\n",
       "98  ['correctness', 'clarity', 'middle']   \n",
       "\n",
       "                               props_a22  annotator_consistency  \\\n",
       "98  ['correctness', 'clarity', 'middle']                   True   \n",
       "\n",
       "          props_gpt4_majority  \\\n",
       "98  ['correctness', 'middle']   \n",
       "\n",
       "                                            res_1.0_1  ...  \\\n",
       "98  {\\n  \"Properties\": [\"correctness\", \"clarity\", ...  ...   \n",
       "\n",
       "                   gpt_props_0.2_3 gpt3.5_0.2_consistency  \\\n",
       "98  ['clarity', 'appropriateness']                      0   \n",
       "\n",
       "                              gpt3.5_0.2_majority humans isCorrect  \\\n",
       "98  ['correctness', 'clarity', 'appropriateness']                1   \n",
       "\n",
       "   gpt isCorrect  comments                                       ground truth  \\\n",
       "98           0.0       NaN  ['correctness', 'clarity','middle','register s...   \n",
       "\n",
       "   property_gpt4                                  res_gpt4_0.0_V3_2  \\\n",
       "98     allusions  {\\n  \"Answer\": \"no\",\\n  \"Explanation\": \"The se...   \n",
       "\n",
       "   property_gpt4_0.0_V3_2  \n",
       "98                     []  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path+\"V3_\"+FEATURE.replace(\" \",\"_\")+\".csv\")\n",
    "df = df[df[\"sentence_id\"]==SID]\n",
    "df = df[df['property_gpt4']==PROP]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "30cec70f-9438-435f-8dc4-2be9d7fcbb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last January, parents filed a federal complaint against Chatham Middle School in Chatham, New Jersey, for forcing students to watch videos that proselytized for Islam.\n"
     ]
    }
   ],
   "source": [
    "sentence = df['text'].iloc[0]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "0530f73c-907c-4a0f-958c-9efc6b94b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSISTANT_MESSAGE = df['res_gpt4_0.0_V3_2'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "45eae8de-aed5-4ab9-a7d4-23b9bc74277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Answer\": \"no\", \"Explanation\": \"The sentence provided does not contain an 'allusion'. An allusion is a figure of speech that references a person, place, thing, or event. These references can be direct or indirect and often rely on the audience's knowledge of the reference to understand its meaning. The sentence in question is a straightforward statement about an event that occurred and does not reference another context, phrase, or cultural knowledge that would require the reader to understand an implied meaning beyond what is explicitly stated.\"}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(ASSISTANT_MESSAGE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "ce8dbf15-6298-4307-b022-573ff0a35eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_MESSAGE = f\"\"\"In the context of '{FEATURE}', '{PROP}' {featuresDict[FEATURE][PROP]}\n",
    "{questionsDict[FEATURE].replace('_PROP_', PROP)} : '{sentence}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "2264608c-0ed7-4d9a-9f02-cdfd1866f1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of 'Language varieties', 'allusions' is the importation of a phrase from another context without explictly naming the other context - intertextuality (it requires cultural knowledge). Examples: 'Cage against the machine' as used in a headline about Nicalas Cage alluding to the band name 'Rage against the machine'\n",
      "Does the following sentence demonstrate or contain 'allusions'? : 'Last January, parents filed a federal complaint against Chatham Middle School in Chatham, New Jersey, for forcing students to watch videos that proselytized for Islam.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(USER_MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "a39a51cb-b608-4ef2-a79d-2bfb0ac9a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = {'messages': [{'role': 'system', 'content': SYSTEM_MESSAGE}, \n",
    "                      {'role': 'user', 'content': USER_MESSAGE}, \n",
    "                      {'role': 'assistant', 'content': json.dumps(json.loads(ASSISTANT_MESSAGE))}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "bad71f86-d731-4f34-bb14-f4015aff3c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the gpt-3.5 architecture. \\nYou are also an expert linguist and grammarian specializing in news text. \\nFormat your response as a JSON object with 'Answer' and 'Explanation' as the keys. \\nThe value of 'Answer' should be either 'yes' or 'no'. Explain your choice in the 'Explanation'.\"}, {\"role\": \"user\", \"content\": \"In the context of 'Language varieties', 'allusions' is the importation of a phrase from another context without explictly naming the other context - intertextuality (it requires cultural knowledge). Examples: 'Cage against the machine' as used in a headline about Nicalas Cage alluding to the band name 'Rage against the machine'\\nDoes the following sentence demonstrate or contain 'allusions'? : 'Last January, parents filed a federal complaint against Chatham Middle School in Chatham, New Jersey, for forcing students to watch videos that proselytized for Islam.'\\n\"}, {\"role\": \"assistant\", \"content\": \"{\\\"Answer\\\": \\\"no\\\", \\\"Explanation\\\": \\\"The sentence provided does not contain an 'allusion'. An allusion is a figure of speech that references a person, place, thing, or event. These references can be direct or indirect and often rely on the audience's knowledge of the reference to understand its meaning. The sentence in question is a straightforward statement about an event that occurred and does not reference another context, phrase, or cultural knowledge that would require the reader to understand an implied meaning beyond what is explicitly stated.\\\"}\"}]}\n"
     ]
    }
   ],
   "source": [
    "s = json.dumps(datum)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc2f29-e3e1-4d80-936a-1229318f73cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf4ec2d-ba27-405f-b544-9d1b541bdfee",
   "metadata": {},
   "source": [
    "# NOT Captured\n",
    "\n",
    "* Aspect - perfect progressive\n",
    "* Figures of argument - antimetabole, abduction, deduction, induction\n",
    "* Figures of word choice - metaplasms, polyptoton, ploce,  'anatanaclasis',\n",
    " 'synonyms', 'rhetorical conditional'\n",
    "* Language varieties - low, high, 'dialects/registers','register shift', 'maxims/proverbs', allusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ace1a1-a3fb-4a5a-b5c5-4d2b29ce9f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51e7781-9a40-42fa-9253-43069a9e0ad2",
   "metadata": {},
   "source": [
    "# FT-25\n",
    "* We get 25 examples for each feature/property. Response is yes/no. No explanations.\n",
    "* Find sentences that are not in the validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "05d88cae-3383-4ab0-a77b-e53f23019059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"gpt-3.5\"\n",
    "SYSTEM_MESSAGE = f\"\"\"You are an expert linguist and grammarian specializing in news text.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "09bcd2fc-8c9c-47b7-acbc-f3d86e689882",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE = \"Aspect\"\n",
    "\n",
    "df = pd.read_csv(\"data/all_features_and_gpt/\"+FEATURE+\".csv\")\n",
    "val_df = pd.read_csv(data_path+\"V3_\"+FEATURE.replace(\" \",\"_\")+\".csv\")\n",
    "val_ids = val_df['sentence_id'].unique()\n",
    "\n",
    "df = df[~df['sentence_id'].isin(val_ids)]\n",
    "df.to_csv(\"data/all_features_and_gpt/\"+FEATURE+\"_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "d65b01d1-d49f-44b0-8c8c-95a9e1c9b2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'perfect', 'progressive', 'perfect progressive']"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROPS = propertiesDict[FEATURE]\n",
    "PROPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "334c79c0-cb9b-4843-87d5-10de5c7a25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP = 'perfect progressive'\n",
    "answer = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "eff4ff33-756e-405f-a548-0cfb27c716e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids =[143,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "26941a3d-eea7-40b4-bd22-8bae59e7949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert linguist and grammarian specializing in news text. \\nFormat your response as a JSON object with 'Answer' as the key. \\nThe value of 'Answer' should be either 'yes' or 'no'.\"}, {\"role\": \"user\", \"content\": \"In the context of 'Aspect', 'perfect progressive' is expressing the end of an ongoing action. Example: 'Rover has been eating a bone.'\\n    Does the following sentence utilize the perfect progressive aspect? : 'Sagacious gun owners have always known that the ultimate goal of gun control extremists such as Chuck Schumer, Nancy Pelosi, Dianne Feinstein, et al., has always been gun confiscation.'\\n    \"}, {\"role\": \"assistant\", \"content\": \"{\\\"Answer\\\": \\\"no\\\"}\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert linguist and grammarian specializing in news text. \\nFormat your response as a JSON object with 'Answer' as the key. \\nThe value of 'Answer' should be either 'yes' or 'no'.\"}, {\"role\": \"user\", \"content\": \"In the context of 'Aspect', 'perfect progressive' is expressing the end of an ongoing action. Example: 'Rover has been eating a bone.'\\n    Does the following sentence utilize the perfect progressive aspect? : 'We are simply asked to take the pope\\u2019s word for it, but given that it follows his astoundingly brazen lie that there was no evidence for Ricca\\u2019s homosexual activity in the first place, we can take the assurance for what it seems to be worth.'\\n    \"}, {\"role\": \"assistant\", \"content\": \"{\\\"Answer\\\": \\\"no\\\"}\"}]}\n"
     ]
    }
   ],
   "source": [
    "for id in ids:\n",
    "    sentence = df[df['sentence_id']==id]['text'].iloc[0]\n",
    "    \n",
    "    USER_MESSAGE = f\"\"\"In the context of '{FEATURE}', '{PROP}' {featuresDict[FEATURE][PROP]}\n",
    "    {questionsDict[FEATURE].replace('_PROP_', PROP)} : '{sentence}'\n",
    "    \"\"\"\n",
    "    \n",
    "    ASSISTANT_MESSAGE = {\"Answer\":answer}\n",
    "    \n",
    "    datum = {'messages': [{'role': 'system', 'content': SYSTEM_MESSAGE}, \n",
    "                          {'role': 'user', 'content': USER_MESSAGE}, \n",
    "                          {'role': 'assistant', 'content': json.dumps(ASSISTANT_MESSAGE)}]}\n",
    "    \n",
    "    s = json.dumps(datum)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1636697-3be8-4ab5-8ce4-f79599204801",
   "metadata": {},
   "source": [
    "# FT-Maj\n",
    "## Steps to create data from noisy human labels\n",
    "\n",
    "* filter out validation sentences\n",
    "* convert to lists and concatenate all human labels\n",
    "* Positive examples:\n",
    "    * Find majority human annotator labels\n",
    "        1. create counter of list items and choose max\n",
    "* Negative examples:\n",
    "    * Find rows where given label is not in any human annotator labels (concatenated list from above)\n",
    "* Append to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "ddb4529a-d8cb-4a2d-bd3f-39669faedfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(featuresDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9621250-04be-40bd-8ce2-a69a2eca1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  [\n",
    "'Aspect',\n",
    "'Emphasis',\n",
    "'Figures of argument',\n",
    "'Figures of word choice',\n",
    "'Language varieties',\n",
    "'Lexical and semantic fields',\n",
    "'Modifying clauses',\n",
    "'Mood',\n",
    "'New words and changing uses',\n",
    "'Parallelism',\n",
    "'Phrases built on nouns',\n",
    "'Phrases built on verbs',\n",
    "'Predication',\n",
    "'Sentence architecture',\n",
    "'Series',\n",
    "'Subject choices',\n",
    "'Tense',\n",
    "'Tropes',\n",
    "'Verb choices'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "57146c8f-f9c8-4c36-abab-ed517a819278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "def concat(a20,a21,a22):\n",
    "\n",
    "    if type(a20) == str:\n",
    "        l0 = ast.literal_eval(a20)\n",
    "    else:\n",
    "        l0 = []\n",
    "\n",
    "    if type(a21) == str:\n",
    "        l1 = ast.literal_eval(a21)\n",
    "    else:\n",
    "        l1 = []\n",
    "    \n",
    "    if type(a22) == str:\n",
    "        l2 = ast.literal_eval(a22)\n",
    "    else:\n",
    "        l2 = []\n",
    "\n",
    "    _all = l0+l1+l2\n",
    "    \n",
    "    return Counter(_all)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "a076f31d-cc61-40ca-8f86-510922a7fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_datum(FEATURE,PROP,sentence):\n",
    "    SYSTEM_MESSAGE = f\"\"\"You are an expert linguist and grammarian specializing in news text.\"\"\"\n",
    "    \n",
    "    USER_MESSAGE = f\"\"\"In the context of grammar '{PROP}' '{FEATURE}' {featuresDict[FEATURE][PROP]}\n",
    "    {questionsDict[FEATURE].replace('_PROP_', PROP)} : '{sentence}'\n",
    "    \"\"\"\n",
    "    \n",
    "    ASSISTANT_MESSAGE = {\"Answer\":answer}\n",
    "    \n",
    "    datum = {'messages': [{'role': 'system', 'content': SYSTEM_MESSAGE}, \n",
    "                          {'role': 'user', 'content': USER_MESSAGE}, \n",
    "                          {'role': 'assistant', 'content': json.dumps(ASSISTANT_MESSAGE)}]}\n",
    "    \n",
    "    s = json.dumps(datum)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "27b91de7-fe50-4790-b6ad-20448f72c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for FEATURE in features:\n",
    "    df = pd.read_csv(\"data/all_features_and_gpt/\"+FEATURE.replace(\" \",\"_\")+\".csv\")\n",
    "    val_df = pd.read_csv(data_path+\"V3_\"+FEATURE.replace(\" \",\"_\")+\".csv\")\n",
    "    val_ids = val_df['sentence_id'].unique()\n",
    "\n",
    "    # filtered DF\n",
    "    df = df[~df['sentence_id'].isin(val_ids)]\n",
    "    # Save to file for later if needed\n",
    "    df.to_csv(\"data/all_features_and_gpt/\"+FEATURE.replace(\" \",\"_\")+\"_filtered.csv\")\n",
    "\n",
    "    df['all_human_anns'] = df.apply(lambda x: concat(x['props_a20'],x['props_a21'],x['props_a22']),axis=1)\n",
    "\n",
    "    PROPS = propertiesDict[FEATURE]\n",
    "\n",
    "    for PROP in PROPS:\n",
    "        for row in df.iterrows():\n",
    "            # print(row[1]['sentence_id'])\n",
    "            sentence = row[1]['text']\n",
    "            # print(sentence)\n",
    "            counter = row[1]['all_human_anns']\n",
    "            if PROP in counter.keys():\n",
    "                if counter[PROP] > 1:\n",
    "                    answer = 'yes'\n",
    "            else:\n",
    "                answer = 'no'\n",
    "\n",
    "            datum = write_datum(FEATURE,PROP,sentence)\n",
    "\n",
    "            #write to file\n",
    "            with open(\"fine-tuning/\"+FEATURE.replace(\" \",\"_\")+\"_FT_data.jsonl\", 'a') as file1:\n",
    "                file1.write(\"\\n\"+datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fc07d-6694-4893-bdca-95964a799dee",
   "metadata": {},
   "source": [
    "NOTE: remove the first line which is `\\n` using awk\n",
    "\n",
    "```\n",
    "cd fine-tuning\n",
    "\n",
    "for FILE in *.jsonl; \n",
    "\tdo awk 'NR>1' $FILE > tmp.jsonl && mv tmp.jsonl $FILE;\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d46ad9-e318-4e68-b99d-b841f52b54f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62eb42-8a6e-4729-86a1-2787bb1cdbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
