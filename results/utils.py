# Utilities

import pandas as pd
import json
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter, defaultdict, OrderedDict
import os
import pymysql
import scipy
from tqdm import tqdm
import ast
import re

hf_token = os.getenv('HF_ACCESS_TOKEN')


def connectDB():
    '''
    Example usage:
    connection = utils.connectDB()
    query = 'SELECT * FROM ebdb.ChatGPT;'
    gpt = pd.read_sql(query, connection)
    '''
    
    MYSQL_HOST = os.getenv('RHETANN_AWS_MYSQL_HOST')
    MYSQL_USER = os.getenv('RHETANN_AWS_MYSQL_USER')
    MYSQL_PASSWORD = os.getenv('RHETANN_AWS_MYSQL_PASSWORD')
    MYSQL_DB = os.getenv('RHETANN_AWS_MYSQL_DB')
    connection = pymysql.connect(host=MYSQL_HOST, user=MYSQL_USER, password=MYSQL_PASSWORD, database=MYSQL_DB)
    
    return connection


    
def get_all_properties(node,all_properties):
    '''
    Parses the JSON recursively to extract the properties
    of the annotated features.
    Returns: list of lists like: ['RB', [{'Modifying_phrases': ['single_word_modifiers']}]]
    '''
    all_properties.append([node['name'],node['properties']])
    if 'children' in node:
        for child in node['children']:
            get_all_properties(child,all_properties)
            
    return all_properties

def getAllSentences(_id,annotations):
    '''
    Input: annotator id, data frame returned by reading from the DB.
        Example:
        query = 'select * from annotations where annotator_id in (20,21,22) and completed=1;'
        annotations = pd.read_sql(query, connection)
    
    For all sentences annotated by the annotator with _id,
    returns sentence id and date_updated along with its features/properties
    '''
    all_sentences = []
    df = annotations[annotations['annotator_id']==_id]
    for row in df.iterrows():
        node = json.loads(row[1]['json_string'])
        technique = node['techniques']
        all_sentences.append([technique,row[1]['sentence_id'],row[1]['date_updated'],get_all_properties(node,[])])
    return all_sentences


def getAllFeatures(all_sentences):
    '''
    Takes as input list of lists generated by getAllSentences(_id)
    Returns a list of lists with sentence id, date updated, and dictionary where the keys are features, and values are the set of properties.
    (this effectively reduces the granularity of the annotations to the sentence level - we do this so we can compare results with ChatGPT)
    '''
    all_features_list = []
    for sentence in all_sentences:

        feature_dict = defaultdict(list)
        
        technique = sentence[0]
        sentence_id = sentence[1]
        date_updated = sentence[2]
        annotation = sentence[3]

        for node in annotation:

            # node: ['RB', [{'Modifying_phrases': ['single_word_modifiers']}]]
            # ignore the node label by taking just the first element: data = [{'Modifying_phrases': ['single_word_modifiers']}]
            data = node[1]

            for _obj in data:

                feature = list(_obj.keys())[0] # 'Modifying_phrases'
                properties = _obj[feature] # ['single_word_modifiers']

                for prop in properties:
                    feature_dict[feature].append(prop.strip())

        # Since features can appear multiple times, and each can have multiple properties, 
        # we take only the unique properties per feature by applying the set() funtion.
        feature_dict = {k: list(set(v)) for k, v in feature_dict.items()}   

        all_features_list.append([technique,sentence_id,date_updated,feature_dict])
    
    return all_features_list

def annotationsToGPTFormat(_id,annotations):
    
    all_sentences = getAllSentences(_id,annotations)   
    all_features_list = getAllFeatures(all_sentences)
    
    df = pd.DataFrame(all_features_list,columns=['technique','sentence_id','date_updated','annotation'])
    df["annotation"] = df["annotation"].apply(lambda x: list(x.items()))
    df = df.explode("annotation")
    df[['feature_id', 'properties']] = pd.DataFrame(df['annotation'].tolist(), index=df.index)
    df = df.drop('annotation', axis=1)
    
    return df


def getGPTFeatures(data):

    results = []
    sentences = data['sentence_id'].unique()
    for sent in tqdm(sentences):
        
        df = data.loc[data['sentence_id'] == sent]
        features = df['feature_id'].unique()
        
        for feature in features:
            responses = list(df.groupby('feature_id').agg(list)[['response']].loc[feature])
            properties = set()
            all_properties = []
            
            for response in responses[0]:
                # print(response)
                if response and type(response) is not float and response[0] == "{":
                    response = response.replace("'","")
                    m = re.search("\[(.*?)\]", response)
                    if m is not None:
                        r = json.loads(m.group())
                        properties.add(str(r))
                        all_properties.append(str(r))
                    else:
                        properties.add("[]")
                        all_properties.append("[]")
                        
            
            results.append([sent,len(properties),properties,all_properties,len(all_properties),feature])

    
    df = pd.DataFrame(results, columns=['sentence_id','count','properties','all_properties','all_count','feature_id'])
    df["properties"] = df["properties"].apply(lambda x: list(x))
    df["properties"] = df["properties"].apply(lambda x: [set(ast.literal_eval(l)) for l in x])
    df["all_properties"] = df["all_properties"].apply(lambda x: [set(ast.literal_eval(l)) for l in x])
    
    return df



def plotPropertyDistributions(feature,a_20,a_21,a_22):
    
    fig, axs = plt.subplots(1,3, sharex=True,figsize=[15,5])
    
    
    features_20 = list(a_20.groupby('feature_id').agg(list).reset_index()['feature_id'])
    if feature in features_20:
        idx_20 = features_20.index(feature)
        properties_20 = a_20.groupby('feature_id').agg(list).reset_index().loc[idx_20][['properties','sentence_id','technique']]
        c20 = Counter([str(l) for l in properties_20['properties']])
    
        axs[0].barh(list(c20.keys()),list(c20.values()))
    else:
        axs[0].barh([],[])

    axs[0].set_title('a20')
    
        
    features_21 = list(a_21.groupby('feature_id').agg(list).reset_index()['feature_id'])
    if feature in features_21:
        idx_21 = features_21.index(feature)
        properties_21 = a_21.groupby('feature_id').agg(list).reset_index().loc[idx_21][['properties','sentence_id','technique']]
        c21 = Counter([str(l) for l in properties_21['properties']])

        axs[1].barh(list(c21.keys()),list(c21.values()))
        
    else:
        axs[1].barh([],[])
    axs[1].set_title('a21')
        
    
    features_22 = list(a_22.groupby('feature_id').agg(list).reset_index()['feature_id'])
    if feature in features_22:
        idx_22 = features_22.index(feature)
        properties_22 = a_22.groupby('feature_id').agg(list).reset_index().loc[idx_22][['properties','sentence_id','technique']]
        c22 = Counter([str(l) for l in properties_22['properties']])

        axs[2].barh(list(c22.keys()),list(c22.values()))
    else:
        axs[2].barh([],[])
    axs[2].set_title('a22')
    
   
    # fig.autofmt_xdate(rotation=90)
    
    fig.suptitle(feature)
    plt.show()


def find_majority(iterable):
    _dict = defaultdict(int)
    maximum = ('', 0 ) # (occurring element, occurrences)
    
    for i in iterable:
        _dict[str(i)] += 1
            
        if _dict[str(i)] > maximum[1]: 
            maximum = (i,_dict[str(i)])
            
    return maximum    
    
def calcAgreement(l1,l2):
    # used for finding agreement beetween majorities
    if type(l1) == str:
        l1 = ast.literal_eval(l1)
        
    if type(l2) == str:
        l2 = ast.literal_eval(l2)
        
    s1 = set(l1)
    s2 = set(l2)
    
    partial = len(s1.intersection(s2)) > 0
    exact = s1 == s2
        
    if exact: return 1
    elif partial: return 0
    else: return -1   

def calcExactAgreement(*items):
    s = set()
    
    for i in items:
        if type(i) == str:
            i = ast.literal_eval(i)
            
        if len(i) > 0:
            s.add(str(i))

    if len(s) == 1:
        return 1
    else:
        return 0


def jaccard_score(a,*b):
    '''
    returns jaccard score for 2 of more sets
    '''
    intersection = a.intersection(*b)
    union = a.union(*b)
    score = len(intersection)/len(union)
    return score

features = ['Aspect',
 'Emphasis',
 'Figures_of_argument',
 'Figures_of_word_choice',
 'Language_of_origin',
 'Language_varieties',
 'Lexical_and_semantic_fields',
 'Modifying_clauses',
 'Modifying_phrases',
 'Mood',
 'New_words_and_changing_uses',
 'Parallelism',
 'Phrases_built_on_nouns',
 'Phrases_built_on_verbs',
 'Predication',
 'Sentence_architecture',
 'Series',
 'Subject_choices',
 'Tense',
 'Tropes',
 'Verb_choices']

## fill in the annotators and gpt predictions. GPT predictions are the majority vote of three prompts

def fillInAnnotations(non_agreed_sentences,a_20,a_21,a_22,gpt_df,FEATURE):

    for row in non_agreed_sentences.iterrows():
        row[1]
        sid = row[1]['sentence_id']

        try:
            props_a20 = a_20.loc[(a_20['sentence_id']==sid)&(a_20['feature_id']==FEATURE)]['properties'].values[0]
            non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a20'] = \
                non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a20'].apply(lambda x: props_a20)
        except:
            pass

        try:
            props_a21 = a_21.loc[(a_21['sentence_id']==sid)&(a_21['feature_id']==FEATURE)]['properties'].values[0]
            non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a21'] = \
                non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a21'].apply(lambda x: props_a21)
        except:
            pass

        try:
            props_a22 = a_22.loc[(a_22['sentence_id']==sid)&(a_22['feature_id']==FEATURE)]['properties'].values[0]
            non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a22'] = \
                non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_a22'].apply(lambda x: props_a22)
        except:
            pass

        try:
            props_gpt = gpt_df.loc[(gpt_df['sentence_id']==sid)&(gpt_df['feature_id']==FEATURE)]['majority_prop'].values[0]    
            non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_gpt'] = \
                non_agreed_sentences.loc[(non_agreed_sentences['sentence_id'] == sid),'props_gpt'].apply(lambda x: props_gpt)
        except:
            pass
        
    return non_agreed_sentences
    
